{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DSC160 Data Science and the Arts - Twomey - Spring 2020 - [dsc160.roberttwomey.com](http://dsc160.roberttwomey.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the pre-trained GPT-2 models\n",
    "\n",
    "Exploring the Generative Pretrained Transformer 2 (GPT-2) from Open AI. This notebook shows you how to generate unconditional text samples (e.g. no prompt) and conditional samples (you provide starter text). \n",
    "\n",
    "Read more about it here: [Better Language Models and Their Implications](https://openai.com/blog/better-language-models/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./content\n",
    "%cd content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/openai/gpt-2\n",
    "%cd gpt-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --user -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p models/124M\n",
    "%run -i download_model.py 124M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unconditional Sampling\n",
    "- Produce three unconditional samples.\n",
    "- After running once, add an additional temperature argument (for instance `--temperature=2.5`) to control the randomness of the sequence completions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'src/generate_unconditional_samples.py' '--modelname=124M' '--nsamples=3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Sampling Activities\n",
    "Try different seed phrases for the conditional samples.\n",
    "- How does the seed change the result?\n",
    "- Do longer seeds produce more coherent output?\n",
    "- Try adding a temperature argument to set randomness of completions on output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i 'src/interactive_conditional_samples.py' '--modelname=124M'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Futher Activity\n",
    "\n",
    "1. Try the other sizes of models. Variants include:\n",
    "  - 117M\n",
    "  - 124M\n",
    "  - 345M\n",
    "  - 355M\n",
    "  - 774M\n",
    "  - Downloading a larger model requires rerunning the python download_model.py command above with a different parameter.\n",
    "  - Using another model requires changing your modelname arugments in the above `%run -i` commands.\n",
    "\n",
    "2. Play with additional parameters for unconditional and conditional generation, particularly:\n",
    "\n",
    "```\n",
    "    length=None,\n",
    "    temperature=1,\n",
    "    top_k=0,\n",
    "```\n",
    "Add these as additional arguments to the above `%run -i` commands.\n",
    "\n",
    "```\n",
    "    :model_name=124M : String, which model to use\n",
    "    :seed=None : Integer seed for random number generators, fix seed to\n",
    "     reproduce results\n",
    "    :nsamples=0 : Number of samples to return, if 0, continues to\n",
    "     generate samples indefinately.\n",
    "    :batch_size=1 : Number of batches (only affects speed/memory).\n",
    "    :length=None : Number of tokens in generated text, if None (default), is\n",
    "     determined by model hyperparameters\n",
    "    :temperature=1 : Float value controlling randomness in boltzmann\n",
    "     distribution. Lower temperature results in less random completions. As the\n",
    "     temperature approaches zero, the model will become deterministic and\n",
    "     repetitive. Higher temperature results in more random completions.\n",
    "    :top_k=0 : Integer value controlling diversity. 1 means only 1 word is\n",
    "     considered for each step (token), resulting in deterministic completions,\n",
    "     while 40 means 40 words are considered at each step. 0 (default) is a\n",
    "     special setting meaning no restrictions. 40 generally is a good value.\n",
    "     :models_dir : path to parent folder containing model subfolders\n",
    "     (i.e. contains the <model_name> folder)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- The `%run` and `%cd`, `%pwd`, etc., above are IPython magic commands. See more [here](https://ipython.readthedocs.io/en/stable/interactive/magics.html).\n",
    "- The lines beginning with `!` are executed as shell commands."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
